{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "hindu-large",
   "metadata": {},
   "source": [
    "## Caputuring all of the D4 Validator results\n",
    "\n",
    "* capture all the D4 agencies + 122 + 81\n",
    "* Siuba code copy/pasted from `loading_gtfs_schedules`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "respected-reality",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gcsfs\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from siuba.dply.vector import row_number\n",
    "from siuba import *\n",
    "\n",
    "fs = gcsfs.GCSFileSystem(project=\"cal-itp-data-infra\")\n",
    "\n",
    "BUCKET_URL = \"gs://gtfs-data/schedule/2021-04-05T00:00:00+00:00\"\n",
    "DATA_URL_TMPL = BUCKET_URL + \"/{itp_id}/{url_number}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "usual-nevada",
   "metadata": {},
   "outputs": [],
   "source": [
    "status = pd.read_csv(BUCKET_URL + \"/status.csv\") >> select(-_.startswith(\"Unnamed\"))\n",
    "\n",
    "status_success = status >> filter(_.status == \"success\")\n",
    "\n",
    "# Note that I've opened an issue in siuba to implement rowwise(),\n",
    "# to replace some cumbersome parts of this group_by -> mutate\n",
    "# could also use df.apply(lambda x: ..., axis = 1)\n",
    "tidy_gtfs_files = (status_success\n",
    "    >> group_by(tmp = row_number(_))\n",
    "    >> mutate(\n",
    "        gtfs_url = lambda d: DATA_URL_TMPL.format(**d.squeeze()),\n",
    "        gtfs_files = lambda d: [fs.listdir(d.squeeze()[\"gtfs_url\"])]\n",
    "    )\n",
    "    >> ungroup()\n",
    "    >> pipe(_.explode(\"gtfs_files\"))\n",
    "    >> mutate(gtfs_file_name = _.gtfs_files.apply(lambda x: x['name']))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "detailed-vietnamese",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     n\n",
       "0  171"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_files = (tidy_gtfs_files\n",
    "  >> filter(_.gtfs_file_name.str.contains(\"validation\\\\.json\"))\n",
    "  >> group_by(tmp = row_number(_))\n",
    "  >> mutate(\n",
    "      validation = lambda d: [json.load(fs.open(d.squeeze().gtfs_file_name))],\n",
    "      notices = lambda d: [d[\"validation\"].iloc[0][\"data\"][\"report\"][\"notices\"]],\n",
    "      n_codes = lambda d: len(d[\"notices\"].iloc[0])\n",
    "  )\n",
    "  >> ungroup()\n",
    ")\n",
    "validation_files >> count()\n",
    "status_success >> count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "quarterly-treatment",
   "metadata": {},
   "outputs": [],
   "source": [
    "notice_codes = (validation_files\n",
    "           .assign(notices = lambda d: d[\"notices\"].transform(pd.DataFrame))\n",
    "          )\n",
    "\n",
    "# note that siuba unnest currently requires resetting index\n",
    "tidy_notice_codes = (notice_codes.reset_index(drop=True)\n",
    "  >> select(_.agency_name, _.itp_id, _.url_number, _.notices)\n",
    "  >> unnest(\"notices\")\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "convenient-landing",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://docs.google.com/spreadsheets/d/1qr49azk6p30mp96_7myKoO-Bb_bXMMn5ZzgbL-uPiPw/gviz/tq?tqx=out:csv&sheet=Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "middle-football",
   "metadata": {},
   "outputs": [],
   "source": [
    "agency_list= df[(df['Caltrans District (int)'] == 4) | (df.ITP_ID ==122) | (df.ITP_ID==81)][['Agency Name', 'ITP_ID']].to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "coordinated-reservoir",
   "metadata": {},
   "outputs": [],
   "source": [
    "tidy_notice_codes[tidy_notice_codes.itp_id.isin([x['ITP_ID'] for x in agency_list])].to_csv('d4_notice_codes.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "received-search",
   "metadata": {},
   "outputs": [],
   "source": [
    "notice_codes_long = tidy_notice_codes.explode(\"notices\").reset_index(drop = True)\n",
    "\n",
    "tidy_notice_details = notice_codes_long.join(\n",
    "        pd.DataFrame(notice_codes_long.notices.tolist())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "experimental-invasion",
   "metadata": {},
   "outputs": [],
   "source": [
    "tidy_notice_details[tidy_notice_details.itp_id.isin([x['ITP_ID'] for x in agency_list])].to_csv('d4_notice_details.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "genuine-perspective",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing Glenn Transit Service\n",
      "missing SamTrans\n",
      "missing Santa Rosa CityBus\n",
      "missing Fairfield and Suisun Transit\n",
      "missing Tri-Valley Wheels\n",
      "missing Union City Transit\n",
      "missing Tri Delta Transit\n",
      "missing San Francisco Bay Ferry\n",
      "missing SolTrans\n",
      "missing Dixon Readi-Ride Transit Services\n",
      "missing USDA Forest Service Southwest Region\n",
      "missing Pleasanton Paratransit Service\n",
      "missing Fremont Paratransit Program\n",
      "missing Oakland International Airport\n",
      "missing Emery Go-Round\n",
      "missing Dumbarton Express\n",
      "missing Berkeley Lab Bus System\n",
      "missing Hill Hopper Shuttle\n",
      "missing San Leandro LINKS\n",
      "missing West Berkeley Shuttle\n",
      "missing CSUEB Shuttle\n",
      "missing Monument Community Shuttle\n",
      "missing Angel Island-Tiburon Ferry Company\n",
      "missing Marin Airporter\n",
      "missing Blue and Gold Fleet\n",
      "missing Metropolitan Transportation Commission\n",
      "missing Mission Bay TMA\n",
      "missing PresidioGo Shuttle\n",
      "missing Commute.org Shuttles\n",
      "missing Foster City Senior Express Shuttle\n",
      "missing San Francisco International Airport\n",
      "missing Menlo Park Shuttles\n",
      "missing Norman Y. Mineta San Jose International Airport\n",
      "missing Mountain View Community Shuttle\n",
      "missing Healdsburg Transportation\n",
      "missing Sonoma County Airport Express\n"
     ]
    }
   ],
   "source": [
    "for x in agency_list:\n",
    "    if x['ITP_ID'] in tidy_notice_codes['itp_id'].values:\n",
    "        pass\n",
    "    else:\n",
    "        print(f'missing {x[\"Agency Name\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inner-paragraph",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
